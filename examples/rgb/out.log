Inspecting Store:	  store ptr %0, ptr %4, align 8
Store value operand is not LoadInst
Inspecting Store:	  store ptr %1, ptr %5, align 8
Store value operand is not LoadInst
Inspecting Store:	  store i32 %2, ptr %6, align 4
Store value operand is not LoadInst
Inspecting Store:	  store i32 %13, ptr %7, align 4
Store value operand is not LoadInst
Inspecting Store:	  store i32 %14, ptr %8, align 4
Store value operand is not LoadInst
Inspecting Store:	  store i32 %21, ptr %26, align 4
Considering load:	  %21 = load i32, ptr %20, align 4
root:	  %19 = sext i32 %18 to i64
root:	  %18 = add nsw i32 %17, 0
root:	  %17 = mul nsw i32 3, %16
root:	i32 3
root:	  %16 = load i32, ptr %7, align 4
root:	  %7 = alloca i32, align 4
root:	  %13 = add i32 %11, %12
root:	  %11 = mul i32 %9, %10
root:	  %9 = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x()
root:	  %10 = call i32 @llvm.nvvm.read.ptx.sreg.ntid.x()
root:	  %12 = call i32 @llvm.nvvm.read.ptx.sreg.tid.x()
store value op resolved after createCoalLoadOrNo.
root:	  %25 = sext i32 %24 to i64
root:	  %24 = add nsw i32 %23, 0
root:	  %23 = mul nsw i32 3, %22
root:	i32 3
root:	  %22 = load i32, ptr %8, align 4
root:	  %8 = alloca i32, align 4
root:	  %14 = call i32 @llvm.nvvm.read.ptx.sreg.tid.x()
store pointer op resolved.
Inspecting Store:	  store i32 %33, ptr %38, align 4
Considering load:	  %33 = load i32, ptr %32, align 4
root:	  %31 = sext i32 %30 to i64
root:	  %30 = add nsw i32 %29, 1
root:	  %29 = mul nsw i32 3, %28
root:	i32 3
root:	  %28 = load i32, ptr %7, align 4
root:	  %7 = alloca i32, align 4
root:	  %13 = add i32 %11, %12
root:	  %11 = mul i32 %9, %10
root:	  %9 = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x()
root:	  %10 = call i32 @llvm.nvvm.read.ptx.sreg.ntid.x()
root:	  %12 = call i32 @llvm.nvvm.read.ptx.sreg.tid.x()
store value op resolved after createCoalLoadOrNo.
root:	  %37 = sext i32 %36 to i64
root:	  %36 = add nsw i32 %35, 1
root:	  %35 = mul nsw i32 3, %34
root:	i32 3
root:	  %34 = load i32, ptr %8, align 4
root:	  %8 = alloca i32, align 4
root:	  %14 = call i32 @llvm.nvvm.read.ptx.sreg.tid.x()
store pointer op resolved.
Inspecting Store:	  store i32 %45, ptr %50, align 4
Considering load:	  %45 = load i32, ptr %44, align 4
root:	  %43 = sext i32 %42 to i64
root:	  %42 = add nsw i32 %41, 2
root:	  %41 = mul nsw i32 3, %40
root:	i32 3
root:	  %40 = load i32, ptr %7, align 4
root:	  %7 = alloca i32, align 4
root:	  %13 = add i32 %11, %12
root:	  %11 = mul i32 %9, %10
root:	  %9 = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x()
root:	  %10 = call i32 @llvm.nvvm.read.ptx.sreg.ntid.x()
root:	  %12 = call i32 @llvm.nvvm.read.ptx.sreg.tid.x()
store value op resolved after createCoalLoadOrNo.
root:	  %49 = sext i32 %48 to i64
root:	  %48 = add nsw i32 %47, 2
root:	  %47 = mul nsw i32 3, %46
root:	i32 3
root:	  %46 = load i32, ptr %8, align 4
root:	  %8 = alloca i32, align 4
root:	  %14 = call i32 @llvm.nvvm.read.ptx.sreg.tid.x()
store pointer op resolved.
Inspecting Store:	  store i32 %59, ptr %63, align 4
Considering load:	  %59 = load i32, ptr %58, align 4
root:	  %57 = sext i32 %56 to i64
root:	  %56 = add nsw i32 96, %55
root:	i32 96
root:	  %55 = load i32, ptr %8, align 4
root:	  %8 = alloca i32, align 4
root:	  %14 = call i32 @llvm.nvvm.read.ptx.sreg.tid.x()
Cannot create CoalLoad.
Inspecting Store:	  store i32 %79, ptr %84, align 4
Store value operand is not LoadInst
Inspecting Store:	  store i32 %99, ptr %104, align 4
Store value operand is not LoadInst
Inspecting Store:	  store i32 %119, ptr %124, align 4
Store value operand is not LoadInst
Inspecting Store:	  store i32 %130, ptr %136, align 4
Considering load:	  %130 = load i32, ptr %129, align 4
root:	  %128 = sext i32 %127 to i64
root:	  %127 = add nsw i32 %126, 0
root:	  %126 = mul nsw i32 3, %125
root:	i32 3
root:	  %125 = load i32, ptr %8, align 4
root:	  %8 = alloca i32, align 4
root:	  %14 = call i32 @llvm.nvvm.read.ptx.sreg.tid.x()
store value op resolved after createCoalLoadOrNo.
root:	  %135 = sext i32 %134 to i64
root:	  %134 = add nsw i32 %133, 0
root:	  %133 = mul nsw i32 3, %132
root:	i32 3
root:	  %132 = load i32, ptr %7, align 4
root:	  %7 = alloca i32, align 4
root:	  %13 = add i32 %11, %12
root:	  %11 = mul i32 %9, %10
root:	  %9 = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x()
root:	  %10 = call i32 @llvm.nvvm.read.ptx.sreg.ntid.x()
root:	  %12 = call i32 @llvm.nvvm.read.ptx.sreg.tid.x()
store pointer op resolved.
Inspecting Store:	  store i32 %142, ptr %148, align 4
Considering load:	  %142 = load i32, ptr %141, align 4
root:	  %140 = sext i32 %139 to i64
root:	  %139 = add nsw i32 %138, 1
root:	  %138 = mul nsw i32 3, %137
root:	i32 3
root:	  %137 = load i32, ptr %8, align 4
root:	  %8 = alloca i32, align 4
root:	  %14 = call i32 @llvm.nvvm.read.ptx.sreg.tid.x()
store value op resolved after createCoalLoadOrNo.
root:	  %147 = sext i32 %146 to i64
root:	  %146 = add nsw i32 %145, 1
root:	  %145 = mul nsw i32 3, %144
root:	i32 3
root:	  %144 = load i32, ptr %7, align 4
root:	  %7 = alloca i32, align 4
root:	  %13 = add i32 %11, %12
root:	  %11 = mul i32 %9, %10
root:	  %9 = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x()
root:	  %10 = call i32 @llvm.nvvm.read.ptx.sreg.ntid.x()
root:	  %12 = call i32 @llvm.nvvm.read.ptx.sreg.tid.x()
store pointer op resolved.
Inspecting Store:	  store i32 %154, ptr %160, align 4
Considering load:	  %154 = load i32, ptr %153, align 4
root:	  %152 = sext i32 %151 to i64
root:	  %151 = add nsw i32 %150, 2
root:	  %150 = mul nsw i32 3, %149
root:	i32 3
root:	  %149 = load i32, ptr %8, align 4
root:	  %8 = alloca i32, align 4
root:	  %14 = call i32 @llvm.nvvm.read.ptx.sreg.tid.x()
store value op resolved after createCoalLoadOrNo.
root:	  %159 = sext i32 %158 to i64
root:	  %158 = add nsw i32 %157, 2
root:	  %157 = mul nsw i32 3, %156
root:	i32 3
root:	  %156 = load i32, ptr %7, align 4
root:	  %7 = alloca i32, align 4
root:	  %13 = add i32 %11, %12
root:	  %11 = mul i32 %9, %10
root:	  %9 = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x()
root:	  %10 = call i32 @llvm.nvvm.read.ptx.sreg.ntid.x()
root:	  %12 = call i32 @llvm.nvvm.read.ptx.sreg.tid.x()
store pointer op resolved.
<<<<<<<<<<<<<<<<<<	All CoalStores	>>>>>>>>>>>>>>>>>>
  store i32 %21, ptr %26, align 4	has potential to be coalesced.
Value Source from Load:	Ptr Source: [Arg ]	Ptr Offset: [Stride = 3]	[StrideOffset = 0]	[GlobalTID]

Ptr Dest of Store:
Ptr Source: [Global _ZZ26rgb_smem_array_interleavedPiS_iE14pixel_smem_src]	@_ZZ26rgb_smem_array_interleavedPiS_iE14pixel_smem_src = internal addrspace(3) global [99 x i32] undef, align 4
Ptr Offset: [Stride = 3]	[StrideOffset = 0]	[LocalThreadIdx]
------------------------------------
  store i32 %33, ptr %38, align 4	has potential to be coalesced.
Value Source from Load:	Ptr Source: [Arg ]	Ptr Offset: [Stride = 3]	[StrideOffset = 1]	[GlobalTID]

Ptr Dest of Store:
Ptr Source: [Global _ZZ26rgb_smem_array_interleavedPiS_iE14pixel_smem_src]	@_ZZ26rgb_smem_array_interleavedPiS_iE14pixel_smem_src = internal addrspace(3) global [99 x i32] undef, align 4
Ptr Offset: [Stride = 3]	[StrideOffset = 1]	[LocalThreadIdx]
------------------------------------
  store i32 %45, ptr %50, align 4	has potential to be coalesced.
Value Source from Load:	Ptr Source: [Arg ]	Ptr Offset: [Stride = 3]	[StrideOffset = 2]	[GlobalTID]

Ptr Dest of Store:
Ptr Source: [Global _ZZ26rgb_smem_array_interleavedPiS_iE14pixel_smem_src]	@_ZZ26rgb_smem_array_interleavedPiS_iE14pixel_smem_src = internal addrspace(3) global [99 x i32] undef, align 4
Ptr Offset: [Stride = 3]	[StrideOffset = 2]	[LocalThreadIdx]
------------------------------------
  store i32 %130, ptr %136, align 4	has potential to be coalesced.
Value Source from Load:	Ptr Source: [Global _ZZ26rgb_smem_array_interleavedPiS_iE14pixel_smem_dst]	Ptr Offset: [Stride = 3]	[StrideOffset = 0]	[LocalThreadIdx]

Ptr Dest of Store:
Ptr Source: [Arg ]	ptr %0
Ptr Offset: [Stride = 3]	[StrideOffset = 0]	[GlobalTID]
------------------------------------
  store i32 %142, ptr %148, align 4	has potential to be coalesced.
Value Source from Load:	Ptr Source: [Global _ZZ26rgb_smem_array_interleavedPiS_iE14pixel_smem_dst]	Ptr Offset: [Stride = 3]	[StrideOffset = 1]	[LocalThreadIdx]

Ptr Dest of Store:
Ptr Source: [Arg ]	ptr %0
Ptr Offset: [Stride = 3]	[StrideOffset = 1]	[GlobalTID]
------------------------------------
  store i32 %154, ptr %160, align 4	has potential to be coalesced.
Value Source from Load:	Ptr Source: [Global _ZZ26rgb_smem_array_interleavedPiS_iE14pixel_smem_dst]	Ptr Offset: [Stride = 3]	[StrideOffset = 2]	[LocalThreadIdx]

Ptr Dest of Store:
Ptr Source: [Arg ]	ptr %0
Ptr Offset: [Stride = 3]	[StrideOffset = 2]	[GlobalTID]
------------------------------------
<<<<<<<<<<<<<<<<<<	All CoalStores Ends	>>>>>>>>>>>>>>>>>>
<<<<<<<<<<<<<<<<<<	CoalStoreGroup 1 Starts	>>>>>>>>>>>>>>>>>>
  store i32 %21, ptr %26, align 4	has potential to be coalesced.
Value Source from Load:	Ptr Source: [Arg ]	Ptr Offset: [Stride = 3]	[StrideOffset = 0]	[GlobalTID]

Ptr Dest of Store:
Ptr Source: [Global _ZZ26rgb_smem_array_interleavedPiS_iE14pixel_smem_src]	@_ZZ26rgb_smem_array_interleavedPiS_iE14pixel_smem_src = internal addrspace(3) global [99 x i32] undef, align 4
Ptr Offset: [Stride = 3]	[StrideOffset = 0]	[LocalThreadIdx]
  store i32 %33, ptr %38, align 4	has potential to be coalesced.
Value Source from Load:	Ptr Source: [Arg ]	Ptr Offset: [Stride = 3]	[StrideOffset = 1]	[GlobalTID]

Ptr Dest of Store:
Ptr Source: [Global _ZZ26rgb_smem_array_interleavedPiS_iE14pixel_smem_src]	@_ZZ26rgb_smem_array_interleavedPiS_iE14pixel_smem_src = internal addrspace(3) global [99 x i32] undef, align 4
Ptr Offset: [Stride = 3]	[StrideOffset = 1]	[LocalThreadIdx]
  store i32 %45, ptr %50, align 4	has potential to be coalesced.
Value Source from Load:	Ptr Source: [Arg ]	Ptr Offset: [Stride = 3]	[StrideOffset = 2]	[GlobalTID]

Ptr Dest of Store:
Ptr Source: [Global _ZZ26rgb_smem_array_interleavedPiS_iE14pixel_smem_src]	@_ZZ26rgb_smem_array_interleavedPiS_iE14pixel_smem_src = internal addrspace(3) global [99 x i32] undef, align 4
Ptr Offset: [Stride = 3]	[StrideOffset = 2]	[LocalThreadIdx]
<<<<<<<<<<<<<<<<<<	CoalStoreGroup 1 Ends	>>>>>>>>>>>>>>>>>>
<<<<<<<<<<<<<<<<<<	CoalStoreGroup 2 Starts	>>>>>>>>>>>>>>>>>>
  store i32 %130, ptr %136, align 4	has potential to be coalesced.
Value Source from Load:	Ptr Source: [Global _ZZ26rgb_smem_array_interleavedPiS_iE14pixel_smem_dst]	Ptr Offset: [Stride = 3]	[StrideOffset = 0]	[LocalThreadIdx]

Ptr Dest of Store:
Ptr Source: [Arg ]	ptr %0
Ptr Offset: [Stride = 3]	[StrideOffset = 0]	[GlobalTID]
  store i32 %142, ptr %148, align 4	has potential to be coalesced.
Value Source from Load:	Ptr Source: [Global _ZZ26rgb_smem_array_interleavedPiS_iE14pixel_smem_dst]	Ptr Offset: [Stride = 3]	[StrideOffset = 1]	[LocalThreadIdx]

Ptr Dest of Store:
Ptr Source: [Arg ]	ptr %0
Ptr Offset: [Stride = 3]	[StrideOffset = 1]	[GlobalTID]
  store i32 %154, ptr %160, align 4	has potential to be coalesced.
Value Source from Load:	Ptr Source: [Global _ZZ26rgb_smem_array_interleavedPiS_iE14pixel_smem_dst]	Ptr Offset: [Stride = 3]	[StrideOffset = 2]	[LocalThreadIdx]

Ptr Dest of Store:
Ptr Source: [Arg ]	ptr %0
Ptr Offset: [Stride = 3]	[StrideOffset = 2]	[GlobalTID]
<<<<<<<<<<<<<<<<<<	CoalStoreGroup 2 Ends	>>>>>>>>>>>>>>>>>>
Stride: 3	inserting offset: 0
Stride: 3	inserting offset: 1
Stride: 3	inserting offset: 2
Removing offset:	0
Removing offset:	1
Removing offset:	2
new address offset [1]:	  %valLoadNewOffsetWithOffset1 = add i32 %valLoadNewOffsetBase1, 0
new GEP for Load:	  %20 = getelementptr inbounds i32, ptr %15, i32 %valLoadNewOffsetWithOffset1
new GEP offset for Store ptr Op shared memory:	  %storePtrGEPNewOffset1 = add i32 %storePtrGEPNewOffsetBase1, 0
new address offset [2]:	  %valLoadNewOffsetWithOffset2 = add i32 %valLoadNewOffsetBase2, 1
new GEP for Load:	  %32 = getelementptr inbounds i32, ptr %27, i32 %valLoadNewOffsetWithOffset2
new GEP offset for Store ptr Op shared memory:	  %storePtrGEPNewOffset2 = add i32 %storePtrGEPNewOffsetBase2, 1
new address offset [3]:	  %valLoadNewOffsetWithOffset3 = add i32 %valLoadNewOffsetBase3, 2
new GEP for Load:	  %44 = getelementptr inbounds i32, ptr %39, i32 %valLoadNewOffsetWithOffset3
new GEP offset for Store ptr Op shared memory:	  %storePtrGEPNewOffset3 = add i32 %storePtrGEPNewOffsetBase3, 2
  %4 = alloca ptr, align 8
  %5 = alloca ptr, align 8
  %6 = alloca i32, align 4
  %7 = alloca i32, align 4
  %8 = alloca i32, align 4
  store ptr %0, ptr %4, align 8
  store ptr %1, ptr %5, align 8
  store i32 %2, ptr %6, align 4
  %9 = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x()
  %10 = call i32 @llvm.nvvm.read.ptx.sreg.ntid.x()
  %11 = mul i32 %9, %10
  %12 = call i32 @llvm.nvvm.read.ptx.sreg.tid.x()
  %multDimIndex = mul i32 %10, %9
  %GlobalTID = add i32 %multDimIndex, %12
  %"multDimIndexScaled#3" = mul i32 %multDimIndex, 3
  %"GlobalTIDScaled#3" = add i32 %"multDimIndexScaled#3", %12
  %13 = add i32 %11, %12
  store i32 %13, ptr %7, align 4
  %14 = call i32 @llvm.nvvm.read.ptx.sreg.tid.x()
  store i32 %14, ptr %8, align 4
  %15 = load ptr, ptr %5, align 8
  %16 = load i32, ptr %7, align 4
  %17 = mul nsw i32 3, %16
  %18 = add nsw i32 %17, 0
  %19 = sext i32 %18 to i64
  %valLoadNewOffsetBase1 = add i32 %"GlobalTIDScaled#3", %10
  %valLoadNewOffsetWithOffset1 = add i32 %valLoadNewOffsetBase1, 0
  %20 = getelementptr inbounds i32, ptr %15, i32 %valLoadNewOffsetWithOffset1
  %21 = load i32, ptr %20, align 4
  %22 = load i32, ptr %8, align 4
  %23 = mul nsw i32 3, %22
  %24 = add nsw i32 %23, 0
  %25 = sext i32 %24 to i64
  %storePtrGEPNewOffsetBase1 = add i32 %12, %10
  %storePtrGEPNewOffset1 = add i32 %storePtrGEPNewOffsetBase1, 0
  %26 = getelementptr inbounds [99 x i32], ptr addrspacecast (ptr addrspace(3) @_ZZ26rgb_smem_array_interleavedPiS_iE14pixel_smem_src to ptr), i64 0, i32 %storePtrGEPNewOffset1
  store i32 %21, ptr %26, align 4
  %27 = load ptr, ptr %5, align 8
  %28 = load i32, ptr %7, align 4
  %29 = mul nsw i32 3, %28
  %30 = add nsw i32 %29, 1
  %31 = sext i32 %30 to i64
  %valLoadNewOffsetBase2 = add i32 %"GlobalTIDScaled#3", %10
  %valLoadNewOffsetWithOffset2 = add i32 %valLoadNewOffsetBase2, 1
  %32 = getelementptr inbounds i32, ptr %27, i32 %valLoadNewOffsetWithOffset2
  %33 = load i32, ptr %32, align 4
  %34 = load i32, ptr %8, align 4
  %35 = mul nsw i32 3, %34
  %36 = add nsw i32 %35, 1
  %37 = sext i32 %36 to i64
  %storePtrGEPNewOffsetBase2 = add i32 %12, %10
  %storePtrGEPNewOffset2 = add i32 %storePtrGEPNewOffsetBase2, 1
  %38 = getelementptr inbounds [99 x i32], ptr addrspacecast (ptr addrspace(3) @_ZZ26rgb_smem_array_interleavedPiS_iE14pixel_smem_src to ptr), i64 0, i32 %storePtrGEPNewOffset2
  store i32 %33, ptr %38, align 4
  %39 = load ptr, ptr %5, align 8
  %40 = load i32, ptr %7, align 4
  %41 = mul nsw i32 3, %40
  %42 = add nsw i32 %41, 2
  %43 = sext i32 %42 to i64
  %valLoadNewOffsetBase3 = add i32 %"GlobalTIDScaled#3", %10
  %valLoadNewOffsetWithOffset3 = add i32 %valLoadNewOffsetBase3, 2
  %44 = getelementptr inbounds i32, ptr %39, i32 %valLoadNewOffsetWithOffset3
  %45 = load i32, ptr %44, align 4
  %46 = load i32, ptr %8, align 4
  %47 = mul nsw i32 3, %46
  %48 = add nsw i32 %47, 2
  %49 = sext i32 %48 to i64
  %storePtrGEPNewOffsetBase3 = add i32 %12, %10
  %storePtrGEPNewOffset3 = add i32 %storePtrGEPNewOffsetBase3, 2
  %50 = getelementptr inbounds [99 x i32], ptr addrspacecast (ptr addrspace(3) @_ZZ26rgb_smem_array_interleavedPiS_iE14pixel_smem_src to ptr), i64 0, i32 %storePtrGEPNewOffset3
  store i32 %45, ptr %50, align 4
  %51 = load i32, ptr %8, align 4
  %52 = icmp slt i32 %51, 3
  br i1 %52, label %53, label %64
<<<<<<<<<<<<<<<<<<	CoalStoreGroup 1 Starts	>>>>>>>>>>>>>>>>>>
  store i32 %21, ptr %26, align 4	has potential to be coalesced.
Value Source from Load:	Ptr Source: [Arg ]	Ptr Offset: [Stride = 3]	[StrideOffset = 0]	[GlobalTID]

Ptr Dest of Store:
Ptr Source: [Global _ZZ26rgb_smem_array_interleavedPiS_iE14pixel_smem_src]	@_ZZ26rgb_smem_array_interleavedPiS_iE14pixel_smem_src = internal addrspace(3) global [99 x i32] undef, align 4
Ptr Offset: [Stride = 3]	[StrideOffset = 0]	[LocalThreadIdx]
  store i32 %33, ptr %38, align 4	has potential to be coalesced.
Value Source from Load:	Ptr Source: [Arg ]	Ptr Offset: [Stride = 3]	[StrideOffset = 1]	[GlobalTID]

Ptr Dest of Store:
Ptr Source: [Global _ZZ26rgb_smem_array_interleavedPiS_iE14pixel_smem_src]	@_ZZ26rgb_smem_array_interleavedPiS_iE14pixel_smem_src = internal addrspace(3) global [99 x i32] undef, align 4
Ptr Offset: [Stride = 3]	[StrideOffset = 1]	[LocalThreadIdx]
  store i32 %45, ptr %50, align 4	has potential to be coalesced.
Value Source from Load:	Ptr Source: [Arg ]	Ptr Offset: [Stride = 3]	[StrideOffset = 2]	[GlobalTID]

Ptr Dest of Store:
Ptr Source: [Global _ZZ26rgb_smem_array_interleavedPiS_iE14pixel_smem_src]	@_ZZ26rgb_smem_array_interleavedPiS_iE14pixel_smem_src = internal addrspace(3) global [99 x i32] undef, align 4
Ptr Offset: [Stride = 3]	[StrideOffset = 2]	[LocalThreadIdx]
<<<<<<<<<<<<<<<<<<	CoalStoreGroup 1 Ends	>>>>>>>>>>>>>>>>>>
Transformed Successfully!
Stride: 3	inserting offset: 0
Stride: 3	inserting offset: 1
Stride: 3	inserting offset: 2
Removing offset:	0
Removing offset:	1
Removing offset:	2
new address offset [1]:	  %valLoadNewOffsetWithOffset12 = add i32 %valLoadNewOffsetBase11, 0
new GEP for Load shared memory:	  %129 = getelementptr inbounds [96 x i32], ptr addrspacecast (ptr addrspace(3) @_ZZ26rgb_smem_array_interleavedPiS_iE14pixel_smem_dst to ptr), i64 0, i32 %valLoadNewOffsetWithOffset12
new GEP offset for Store ptr Op:	  %storePtrGEPNewOffset14 = add i32 %storePtrGEPNewOffsetBase13, 0
new address offset [2]:	  %valLoadNewOffsetWithOffset26 = add i32 %valLoadNewOffsetBase25, 1
new GEP for Load shared memory:	  %141 = getelementptr inbounds [96 x i32], ptr addrspacecast (ptr addrspace(3) @_ZZ26rgb_smem_array_interleavedPiS_iE14pixel_smem_dst to ptr), i64 0, i32 %valLoadNewOffsetWithOffset26
new GEP offset for Store ptr Op:	  %storePtrGEPNewOffset28 = add i32 %storePtrGEPNewOffsetBase27, 1
new address offset [3]:	  %valLoadNewOffsetWithOffset310 = add i32 %valLoadNewOffsetBase39, 2
new GEP for Load shared memory:	  %153 = getelementptr inbounds [96 x i32], ptr addrspacecast (ptr addrspace(3) @_ZZ26rgb_smem_array_interleavedPiS_iE14pixel_smem_dst to ptr), i64 0, i32 %valLoadNewOffsetWithOffset310
new GEP offset for Store ptr Op:	  %storePtrGEPNewOffset312 = add i32 %storePtrGEPNewOffsetBase311, 2
  %65 = load i32, ptr %8, align 4
  %66 = mul nsw i32 3, %65
  %67 = add nsw i32 %66, 0
  %68 = sext i32 %67 to i64
  %69 = getelementptr inbounds [99 x i32], ptr addrspacecast (ptr addrspace(3) @_ZZ26rgb_smem_array_interleavedPiS_iE14pixel_smem_src to ptr), i64 0, i64 %68
  %70 = load i32, ptr %69, align 4
  %71 = load i32, ptr %8, align 4
  %72 = add nsw i32 %71, 1
  %73 = mul nsw i32 3, %72
  %74 = add nsw i32 %73, 0
  %75 = sext i32 %74 to i64
  %76 = getelementptr inbounds [99 x i32], ptr addrspacecast (ptr addrspace(3) @_ZZ26rgb_smem_array_interleavedPiS_iE14pixel_smem_src to ptr), i64 0, i64 %75
  %77 = load i32, ptr %76, align 4
  %78 = add nsw i32 %70, %77
  %79 = ashr i32 %78, 1
  %80 = load i32, ptr %8, align 4
  %81 = mul nsw i32 3, %80
  %82 = add nsw i32 %81, 0
  %83 = sext i32 %82 to i64
  %84 = getelementptr inbounds [96 x i32], ptr addrspacecast (ptr addrspace(3) @_ZZ26rgb_smem_array_interleavedPiS_iE14pixel_smem_dst to ptr), i64 0, i64 %83
  store i32 %79, ptr %84, align 4
  %85 = load i32, ptr %8, align 4
  %86 = mul nsw i32 3, %85
  %87 = add nsw i32 %86, 1
  %88 = sext i32 %87 to i64
  %89 = getelementptr inbounds [99 x i32], ptr addrspacecast (ptr addrspace(3) @_ZZ26rgb_smem_array_interleavedPiS_iE14pixel_smem_src to ptr), i64 0, i64 %88
  %90 = load i32, ptr %89, align 4
  %91 = load i32, ptr %8, align 4
  %92 = add nsw i32 %91, 1
  %93 = mul nsw i32 3, %92
  %94 = add nsw i32 %93, 1
  %95 = sext i32 %94 to i64
  %96 = getelementptr inbounds [99 x i32], ptr addrspacecast (ptr addrspace(3) @_ZZ26rgb_smem_array_interleavedPiS_iE14pixel_smem_src to ptr), i64 0, i64 %95
  %97 = load i32, ptr %96, align 4
  %98 = add nsw i32 %90, %97
  %99 = ashr i32 %98, 1
  %100 = load i32, ptr %8, align 4
  %101 = mul nsw i32 3, %100
  %102 = add nsw i32 %101, 1
  %103 = sext i32 %102 to i64
  %104 = getelementptr inbounds [96 x i32], ptr addrspacecast (ptr addrspace(3) @_ZZ26rgb_smem_array_interleavedPiS_iE14pixel_smem_dst to ptr), i64 0, i64 %103
  store i32 %99, ptr %104, align 4
  %105 = load i32, ptr %8, align 4
  %106 = mul nsw i32 3, %105
  %107 = add nsw i32 %106, 2
  %108 = sext i32 %107 to i64
  %109 = getelementptr inbounds [99 x i32], ptr addrspacecast (ptr addrspace(3) @_ZZ26rgb_smem_array_interleavedPiS_iE14pixel_smem_src to ptr), i64 0, i64 %108
  %110 = load i32, ptr %109, align 4
  %111 = load i32, ptr %8, align 4
  %112 = add nsw i32 %111, 1
  %113 = mul nsw i32 3, %112
  %114 = add nsw i32 %113, 2
  %115 = sext i32 %114 to i64
  %116 = getelementptr inbounds [99 x i32], ptr addrspacecast (ptr addrspace(3) @_ZZ26rgb_smem_array_interleavedPiS_iE14pixel_smem_src to ptr), i64 0, i64 %115
  %117 = load i32, ptr %116, align 4
  %118 = add nsw i32 %110, %117
  %119 = ashr i32 %118, 1
  %120 = load i32, ptr %8, align 4
  %121 = mul nsw i32 3, %120
  %122 = add nsw i32 %121, 2
  %123 = sext i32 %122 to i64
  %124 = getelementptr inbounds [96 x i32], ptr addrspacecast (ptr addrspace(3) @_ZZ26rgb_smem_array_interleavedPiS_iE14pixel_smem_dst to ptr), i64 0, i64 %123
  store i32 %119, ptr %124, align 4
  %125 = load i32, ptr %8, align 4
  %126 = mul nsw i32 3, %125
  %127 = add nsw i32 %126, 0
  %128 = sext i32 %127 to i64
  %valLoadNewOffsetBase11 = add i32 %12, %10
  %valLoadNewOffsetWithOffset12 = add i32 %valLoadNewOffsetBase11, 0
  %129 = getelementptr inbounds [96 x i32], ptr addrspacecast (ptr addrspace(3) @_ZZ26rgb_smem_array_interleavedPiS_iE14pixel_smem_dst to ptr), i64 0, i32 %valLoadNewOffsetWithOffset12
  %130 = load i32, ptr %129, align 4
  %131 = load ptr, ptr %4, align 8
  %132 = load i32, ptr %7, align 4
  %133 = mul nsw i32 3, %132
  %134 = add nsw i32 %133, 0
  %135 = sext i32 %134 to i64
  %storePtrGEPNewOffsetBase13 = add i32 %"GlobalTIDScaled#3", %10
  %storePtrGEPNewOffset14 = add i32 %storePtrGEPNewOffsetBase13, 0
  %136 = getelementptr inbounds i32, ptr %131, i32 %storePtrGEPNewOffset14
  store i32 %130, ptr %136, align 4
  %137 = load i32, ptr %8, align 4
  %138 = mul nsw i32 3, %137
  %139 = add nsw i32 %138, 1
  %140 = sext i32 %139 to i64
  %valLoadNewOffsetBase25 = add i32 %12, %10
  %valLoadNewOffsetWithOffset26 = add i32 %valLoadNewOffsetBase25, 1
  %141 = getelementptr inbounds [96 x i32], ptr addrspacecast (ptr addrspace(3) @_ZZ26rgb_smem_array_interleavedPiS_iE14pixel_smem_dst to ptr), i64 0, i32 %valLoadNewOffsetWithOffset26
  %142 = load i32, ptr %141, align 4
  %143 = load ptr, ptr %4, align 8
  %144 = load i32, ptr %7, align 4
  %145 = mul nsw i32 3, %144
  %146 = add nsw i32 %145, 1
  %147 = sext i32 %146 to i64
  %storePtrGEPNewOffsetBase27 = add i32 %"GlobalTIDScaled#3", %10
  %storePtrGEPNewOffset28 = add i32 %storePtrGEPNewOffsetBase27, 1
  %148 = getelementptr inbounds i32, ptr %143, i32 %storePtrGEPNewOffset28
  store i32 %142, ptr %148, align 4
  %149 = load i32, ptr %8, align 4
  %150 = mul nsw i32 3, %149
  %151 = add nsw i32 %150, 2
  %152 = sext i32 %151 to i64
  %valLoadNewOffsetBase39 = add i32 %12, %10
  %valLoadNewOffsetWithOffset310 = add i32 %valLoadNewOffsetBase39, 2
  %153 = getelementptr inbounds [96 x i32], ptr addrspacecast (ptr addrspace(3) @_ZZ26rgb_smem_array_interleavedPiS_iE14pixel_smem_dst to ptr), i64 0, i32 %valLoadNewOffsetWithOffset310
  %154 = load i32, ptr %153, align 4
  %155 = load ptr, ptr %4, align 8
  %156 = load i32, ptr %7, align 4
  %157 = mul nsw i32 3, %156
  %158 = add nsw i32 %157, 2
  %159 = sext i32 %158 to i64
  %storePtrGEPNewOffsetBase311 = add i32 %"GlobalTIDScaled#3", %10
  %storePtrGEPNewOffset312 = add i32 %storePtrGEPNewOffsetBase311, 2
  %160 = getelementptr inbounds i32, ptr %155, i32 %storePtrGEPNewOffset312
  store i32 %154, ptr %160, align 4
  ret void
<<<<<<<<<<<<<<<<<<	CoalStoreGroup 2 Starts	>>>>>>>>>>>>>>>>>>
  store i32 %130, ptr %136, align 4	has potential to be coalesced.
Value Source from Load:	Ptr Source: [Global _ZZ26rgb_smem_array_interleavedPiS_iE14pixel_smem_dst]	Ptr Offset: [Stride = 3]	[StrideOffset = 0]	[LocalThreadIdx]

Ptr Dest of Store:
Ptr Source: [Arg ]	ptr %0
Ptr Offset: [Stride = 3]	[StrideOffset = 0]	[GlobalTID]
  store i32 %142, ptr %148, align 4	has potential to be coalesced.
Value Source from Load:	Ptr Source: [Global _ZZ26rgb_smem_array_interleavedPiS_iE14pixel_smem_dst]	Ptr Offset: [Stride = 3]	[StrideOffset = 1]	[LocalThreadIdx]

Ptr Dest of Store:
Ptr Source: [Arg ]	ptr %0
Ptr Offset: [Stride = 3]	[StrideOffset = 1]	[GlobalTID]
  store i32 %154, ptr %160, align 4	has potential to be coalesced.
Value Source from Load:	Ptr Source: [Global _ZZ26rgb_smem_array_interleavedPiS_iE14pixel_smem_dst]	Ptr Offset: [Stride = 3]	[StrideOffset = 2]	[LocalThreadIdx]

Ptr Dest of Store:
Ptr Source: [Arg ]	ptr %0
Ptr Offset: [Stride = 3]	[StrideOffset = 2]	[GlobalTID]
<<<<<<<<<<<<<<<<<<	CoalStoreGroup 2 Ends	>>>>>>>>>>>>>>>>>>
Transformed Successfully!
<<<<<<<<<<<<<<<<<<	Modified LLVM IR	>>>>>>>>>>>>>>>>>>
  %4 = alloca ptr, align 8
  %5 = alloca ptr, align 8
  %6 = alloca i32, align 4
  %7 = alloca i32, align 4
  %8 = alloca i32, align 4
  store ptr %0, ptr %4, align 8
  store ptr %1, ptr %5, align 8
  store i32 %2, ptr %6, align 4
  %9 = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x()
  %10 = call i32 @llvm.nvvm.read.ptx.sreg.ntid.x()
  %11 = mul i32 %9, %10
  %12 = call i32 @llvm.nvvm.read.ptx.sreg.tid.x()
  %multDimIndex = mul i32 %10, %9
  %GlobalTID = add i32 %multDimIndex, %12
  %"multDimIndexScaled#3" = mul i32 %multDimIndex, 3
  %"GlobalTIDScaled#3" = add i32 %"multDimIndexScaled#3", %12
  %13 = add i32 %11, %12
  store i32 %13, ptr %7, align 4
  %14 = call i32 @llvm.nvvm.read.ptx.sreg.tid.x()
  store i32 %14, ptr %8, align 4
  %15 = load ptr, ptr %5, align 8
  %16 = load i32, ptr %7, align 4
  %17 = mul nsw i32 3, %16
  %18 = add nsw i32 %17, 0
  %19 = sext i32 %18 to i64
  %valLoadNewOffsetBase1 = add i32 %"GlobalTIDScaled#3", %10
  %valLoadNewOffsetWithOffset1 = add i32 %valLoadNewOffsetBase1, 0
  %20 = getelementptr inbounds i32, ptr %15, i32 %valLoadNewOffsetWithOffset1
  %21 = load i32, ptr %20, align 4
  %22 = load i32, ptr %8, align 4
  %23 = mul nsw i32 3, %22
  %24 = add nsw i32 %23, 0
  %25 = sext i32 %24 to i64
  %storePtrGEPNewOffsetBase1 = add i32 %12, %10
  %storePtrGEPNewOffset1 = add i32 %storePtrGEPNewOffsetBase1, 0
  %26 = getelementptr inbounds [99 x i32], ptr addrspacecast (ptr addrspace(3) @_ZZ26rgb_smem_array_interleavedPiS_iE14pixel_smem_src to ptr), i64 0, i32 %storePtrGEPNewOffset1
  store i32 %21, ptr %26, align 4
  %27 = load ptr, ptr %5, align 8
  %28 = load i32, ptr %7, align 4
  %29 = mul nsw i32 3, %28
  %30 = add nsw i32 %29, 1
  %31 = sext i32 %30 to i64
  %valLoadNewOffsetBase2 = add i32 %"GlobalTIDScaled#3", %10
  %valLoadNewOffsetWithOffset2 = add i32 %valLoadNewOffsetBase2, 1
  %32 = getelementptr inbounds i32, ptr %27, i32 %valLoadNewOffsetWithOffset2
  %33 = load i32, ptr %32, align 4
  %34 = load i32, ptr %8, align 4
  %35 = mul nsw i32 3, %34
  %36 = add nsw i32 %35, 1
  %37 = sext i32 %36 to i64
  %storePtrGEPNewOffsetBase2 = add i32 %12, %10
  %storePtrGEPNewOffset2 = add i32 %storePtrGEPNewOffsetBase2, 1
  %38 = getelementptr inbounds [99 x i32], ptr addrspacecast (ptr addrspace(3) @_ZZ26rgb_smem_array_interleavedPiS_iE14pixel_smem_src to ptr), i64 0, i32 %storePtrGEPNewOffset2
  store i32 %33, ptr %38, align 4
  %39 = load ptr, ptr %5, align 8
  %40 = load i32, ptr %7, align 4
  %41 = mul nsw i32 3, %40
  %42 = add nsw i32 %41, 2
  %43 = sext i32 %42 to i64
  %valLoadNewOffsetBase3 = add i32 %"GlobalTIDScaled#3", %10
  %valLoadNewOffsetWithOffset3 = add i32 %valLoadNewOffsetBase3, 2
  %44 = getelementptr inbounds i32, ptr %39, i32 %valLoadNewOffsetWithOffset3
  %45 = load i32, ptr %44, align 4
  %46 = load i32, ptr %8, align 4
  %47 = mul nsw i32 3, %46
  %48 = add nsw i32 %47, 2
  %49 = sext i32 %48 to i64
  %storePtrGEPNewOffsetBase3 = add i32 %12, %10
  %storePtrGEPNewOffset3 = add i32 %storePtrGEPNewOffsetBase3, 2
  %50 = getelementptr inbounds [99 x i32], ptr addrspacecast (ptr addrspace(3) @_ZZ26rgb_smem_array_interleavedPiS_iE14pixel_smem_src to ptr), i64 0, i32 %storePtrGEPNewOffset3
  store i32 %45, ptr %50, align 4
  %51 = load i32, ptr %8, align 4
  %52 = icmp slt i32 %51, 3
  br i1 %52, label %53, label %64
  %54 = load ptr, ptr %5, align 8
  %55 = load i32, ptr %8, align 4
  %56 = add nsw i32 96, %55
  %57 = sext i32 %56 to i64
  %58 = getelementptr inbounds i32, ptr %54, i64 %57
  %59 = load i32, ptr %58, align 4
  %60 = load i32, ptr %8, align 4
  %61 = add nsw i32 96, %60
  %62 = sext i32 %61 to i64
  %63 = getelementptr inbounds [99 x i32], ptr addrspacecast (ptr addrspace(3) @_ZZ26rgb_smem_array_interleavedPiS_iE14pixel_smem_src to ptr), i64 0, i64 %62
  store i32 %59, ptr %63, align 4
  br label %64
  %65 = load i32, ptr %8, align 4
  %66 = mul nsw i32 3, %65
  %67 = add nsw i32 %66, 0
  %68 = sext i32 %67 to i64
  %69 = getelementptr inbounds [99 x i32], ptr addrspacecast (ptr addrspace(3) @_ZZ26rgb_smem_array_interleavedPiS_iE14pixel_smem_src to ptr), i64 0, i64 %68
  %70 = load i32, ptr %69, align 4
  %71 = load i32, ptr %8, align 4
  %72 = add nsw i32 %71, 1
  %73 = mul nsw i32 3, %72
  %74 = add nsw i32 %73, 0
  %75 = sext i32 %74 to i64
  %76 = getelementptr inbounds [99 x i32], ptr addrspacecast (ptr addrspace(3) @_ZZ26rgb_smem_array_interleavedPiS_iE14pixel_smem_src to ptr), i64 0, i64 %75
  %77 = load i32, ptr %76, align 4
  %78 = add nsw i32 %70, %77
  %79 = ashr i32 %78, 1
  %80 = load i32, ptr %8, align 4
  %81 = mul nsw i32 3, %80
  %82 = add nsw i32 %81, 0
  %83 = sext i32 %82 to i64
  %84 = getelementptr inbounds [96 x i32], ptr addrspacecast (ptr addrspace(3) @_ZZ26rgb_smem_array_interleavedPiS_iE14pixel_smem_dst to ptr), i64 0, i64 %83
  store i32 %79, ptr %84, align 4
  %85 = load i32, ptr %8, align 4
  %86 = mul nsw i32 3, %85
  %87 = add nsw i32 %86, 1
  %88 = sext i32 %87 to i64
  %89 = getelementptr inbounds [99 x i32], ptr addrspacecast (ptr addrspace(3) @_ZZ26rgb_smem_array_interleavedPiS_iE14pixel_smem_src to ptr), i64 0, i64 %88
  %90 = load i32, ptr %89, align 4
  %91 = load i32, ptr %8, align 4
  %92 = add nsw i32 %91, 1
  %93 = mul nsw i32 3, %92
  %94 = add nsw i32 %93, 1
  %95 = sext i32 %94 to i64
  %96 = getelementptr inbounds [99 x i32], ptr addrspacecast (ptr addrspace(3) @_ZZ26rgb_smem_array_interleavedPiS_iE14pixel_smem_src to ptr), i64 0, i64 %95
  %97 = load i32, ptr %96, align 4
  %98 = add nsw i32 %90, %97
  %99 = ashr i32 %98, 1
  %100 = load i32, ptr %8, align 4
  %101 = mul nsw i32 3, %100
  %102 = add nsw i32 %101, 1
  %103 = sext i32 %102 to i64
  %104 = getelementptr inbounds [96 x i32], ptr addrspacecast (ptr addrspace(3) @_ZZ26rgb_smem_array_interleavedPiS_iE14pixel_smem_dst to ptr), i64 0, i64 %103
  store i32 %99, ptr %104, align 4
  %105 = load i32, ptr %8, align 4
  %106 = mul nsw i32 3, %105
  %107 = add nsw i32 %106, 2
  %108 = sext i32 %107 to i64
  %109 = getelementptr inbounds [99 x i32], ptr addrspacecast (ptr addrspace(3) @_ZZ26rgb_smem_array_interleavedPiS_iE14pixel_smem_src to ptr), i64 0, i64 %108
  %110 = load i32, ptr %109, align 4
  %111 = load i32, ptr %8, align 4
  %112 = add nsw i32 %111, 1
  %113 = mul nsw i32 3, %112
  %114 = add nsw i32 %113, 2
  %115 = sext i32 %114 to i64
  %116 = getelementptr inbounds [99 x i32], ptr addrspacecast (ptr addrspace(3) @_ZZ26rgb_smem_array_interleavedPiS_iE14pixel_smem_src to ptr), i64 0, i64 %115
  %117 = load i32, ptr %116, align 4
  %118 = add nsw i32 %110, %117
  %119 = ashr i32 %118, 1
  %120 = load i32, ptr %8, align 4
  %121 = mul nsw i32 3, %120
  %122 = add nsw i32 %121, 2
  %123 = sext i32 %122 to i64
  %124 = getelementptr inbounds [96 x i32], ptr addrspacecast (ptr addrspace(3) @_ZZ26rgb_smem_array_interleavedPiS_iE14pixel_smem_dst to ptr), i64 0, i64 %123
  store i32 %119, ptr %124, align 4
  %125 = load i32, ptr %8, align 4
  %126 = mul nsw i32 3, %125
  %127 = add nsw i32 %126, 0
  %128 = sext i32 %127 to i64
  %valLoadNewOffsetBase11 = add i32 %12, %10
  %valLoadNewOffsetWithOffset12 = add i32 %valLoadNewOffsetBase11, 0
  %129 = getelementptr inbounds [96 x i32], ptr addrspacecast (ptr addrspace(3) @_ZZ26rgb_smem_array_interleavedPiS_iE14pixel_smem_dst to ptr), i64 0, i32 %valLoadNewOffsetWithOffset12
  %130 = load i32, ptr %129, align 4
  %131 = load ptr, ptr %4, align 8
  %132 = load i32, ptr %7, align 4
  %133 = mul nsw i32 3, %132
  %134 = add nsw i32 %133, 0
  %135 = sext i32 %134 to i64
  %storePtrGEPNewOffsetBase13 = add i32 %"GlobalTIDScaled#3", %10
  %storePtrGEPNewOffset14 = add i32 %storePtrGEPNewOffsetBase13, 0
  %136 = getelementptr inbounds i32, ptr %131, i32 %storePtrGEPNewOffset14
  store i32 %130, ptr %136, align 4
  %137 = load i32, ptr %8, align 4
  %138 = mul nsw i32 3, %137
  %139 = add nsw i32 %138, 1
  %140 = sext i32 %139 to i64
  %valLoadNewOffsetBase25 = add i32 %12, %10
  %valLoadNewOffsetWithOffset26 = add i32 %valLoadNewOffsetBase25, 1
  %141 = getelementptr inbounds [96 x i32], ptr addrspacecast (ptr addrspace(3) @_ZZ26rgb_smem_array_interleavedPiS_iE14pixel_smem_dst to ptr), i64 0, i32 %valLoadNewOffsetWithOffset26
  %142 = load i32, ptr %141, align 4
  %143 = load ptr, ptr %4, align 8
  %144 = load i32, ptr %7, align 4
  %145 = mul nsw i32 3, %144
  %146 = add nsw i32 %145, 1
  %147 = sext i32 %146 to i64
  %storePtrGEPNewOffsetBase27 = add i32 %"GlobalTIDScaled#3", %10
  %storePtrGEPNewOffset28 = add i32 %storePtrGEPNewOffsetBase27, 1
  %148 = getelementptr inbounds i32, ptr %143, i32 %storePtrGEPNewOffset28
  store i32 %142, ptr %148, align 4
  %149 = load i32, ptr %8, align 4
  %150 = mul nsw i32 3, %149
  %151 = add nsw i32 %150, 2
  %152 = sext i32 %151 to i64
  %valLoadNewOffsetBase39 = add i32 %12, %10
  %valLoadNewOffsetWithOffset310 = add i32 %valLoadNewOffsetBase39, 2
  %153 = getelementptr inbounds [96 x i32], ptr addrspacecast (ptr addrspace(3) @_ZZ26rgb_smem_array_interleavedPiS_iE14pixel_smem_dst to ptr), i64 0, i32 %valLoadNewOffsetWithOffset310
  %154 = load i32, ptr %153, align 4
  %155 = load ptr, ptr %4, align 8
  %156 = load i32, ptr %7, align 4
  %157 = mul nsw i32 3, %156
  %158 = add nsw i32 %157, 2
  %159 = sext i32 %158 to i64
  %storePtrGEPNewOffsetBase311 = add i32 %"GlobalTIDScaled#3", %10
  %storePtrGEPNewOffset312 = add i32 %storePtrGEPNewOffsetBase311, 2
  %160 = getelementptr inbounds i32, ptr %155, i32 %storePtrGEPNewOffset312
  store i32 %154, ptr %160, align 4
  ret void
